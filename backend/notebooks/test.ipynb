{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489958e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents import create_deep_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from  langgraph.checkpoint.memory import MemorySaver\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d8d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from tavily import TavilyClient\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "@tool\n",
    "def internet_search(\n",
    "    query: str,\n",
    "    max_results: int = 5,\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "    include_raw_content: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Search the internet for information.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "        max_results: The maximum number of search results to return\n",
    "\n",
    "        \n",
    "    Returns:\n",
    "        Search results as a dict\n",
    "    \"\"\"\n",
    "    return tavily_client.search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c570a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "        api_key=os.environ.get(\"OLLAMA_API_KEY\"),\n",
    "        model=\"gpt-oss:120b\",\n",
    "        base_url=\"https://api.ollama.com\",\n",
    "        temperature=0.0,\n",
    "    )\n",
    "# llm = ChatOllama(\n",
    "#     model=\"gpt-oss:120b-cloud\", # Use the model you pulled\n",
    "#     base_url=\"http://localhost:11434\", # Point to the local Ollama server\n",
    "#     temperature=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7e3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = open(\"../promt.md\",\"r\",encoding=\"utf8\").read()\n",
    "agent_graph = create_deep_agent(\n",
    "    model=llm,\n",
    "    tools=[internet_search],\n",
    "    # system_prompt=prompt,\n",
    "    checkpointer=MemorySaver(), # This enables Short-Term Chat Memory\n",
    "    # response_format={\"content\":\"answer of asked response\",\"tools_used\":[\"tool1\",\"tool2\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66456b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"session_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6d992db",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = agent_graph.stream(\n",
    "    {\"messages\": [(\"user\", \"write a plan to search who is prime minister of india using given tools\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cedb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = \"\"\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        # Filter out intermediate tool calls, show only AI response\n",
    "        if last_msg.type == \"ai\" and not last_msg.tool_calls:\n",
    "            final_answer = last_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22e5338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Plan to Find the Current Prime Minister of India Using the Available Tools**\n",
      "\n",
      "| # | Objective / Sub‑task | Tools to Use | How to Use the Tool | Expected Result |\n",
      "|---|----------------------|--------------|---------------------|-----------------|\n",
      "| 1 | **Perform an Internet Search** (the quickest way to get up‑to‑date information). | `internet_search` | ```json { \"query\": \"current prime minister of India 2024\", \"max_results\": 5, \"include_raw_content\": true, \"topic\": \"\" } ``` | A short list of recent, reliable web pages (e.g., Wikipedia, official Indian government site, reputable news outlet) that name the incumbent prime minister. |\n",
      "| 2 | **Extract the Name from the Top Result** | – (no tool needed; just read the returned data) | Look at the titles/snippets or the raw HTML/text of the highest‑ranked result. Pick the most trustworthy source (official government domain, Wikipedia, major newspaper). | The exact name of the current prime minister (e.g., “Narendra Modi”). |\n",
      "| 3 *(optional)* | **Validate with a Second Source** (to avoid a stale or mis‑parsed result). | `internet_search` (again) | ```json { \"query\": \"Narendra Modi prime minister of India official website\", \"max_results\": 3, \"include_raw_content\": true, \"topic\": \"\" } ``` | Confirmation from an official source (e.g., india.gov.in) that the name obtained in step 2 is correct. |\n",
      "| 4 *(optional)* | **Persist the Answer Locally** (useful for later reference without another web call). | `write_file` | ```json { \"file_path\": \"/tmp/prime_minister_india.txt\", \"content\": \"Prime Minister of India (as of 2024): Narendra Modi\" } ``` | A local text file containing the answer. |\n",
      "| 5 *(fallback)* | **Search a Local Knowledge Base** (if the environment has no internet access). | `grep` (or `glob` + `grep`) | ```json { \"pattern\": \"prime minister of india\", \"glob\": \"**/*.md\", \"output_mode\": \"content\", \"path\": \"/\" } ``` | Any locally stored encyclopedia, markdown, or text file that mentions the prime minister; extract the name from the matching line(s). |\n",
      "| 6 *(fallback continuation)* | **Read the Matching File** (to view the extracted snippet). | `read_file` | ```json { \"file_path\": \"<path returned by grep>\", \"offset\": 0, \"limit\": 50 } ``` | The snippet giving the prime minister’s name. |\n",
      "\n",
      "### Execution Flow Summary\n",
      "1. **Primary approach** – Use `internet_search` to get up‑to‑date info.  \n",
      "2. **Parse** the most authoritative result to obtain the name.  \n",
      "3. **(Optional) Cross‑verify** with a second search to ensure accuracy.  \n",
      "4. **(Optional) Store** the answer locally with `write_file`.  \n",
      "5. **If internet is unavailable**, fall back to a local text‑search using `grep`/`glob` and read the file.  \n",
      "\n",
      "### Why This Plan Works\n",
      "- **Speed & Accuracy:** Internet search gives the freshest political data; official sites and Wikipedia are reliable sources.  \n",
      "- **Redundancy:** A second verification step guards against outdated cache or mis‑parsing.  \n",
      "- **Persistence:** Saving to a file avoids repeated searches if the user later asks for the same fact.  \n",
      "- **Graceful Degradation:** The fallback to `grep` ensures the task can still be completed when network access is restricted.\n",
      "\n",
      "Feel free to follow the steps in the order shown, adapting optional parts as needed based on the environment’s capabilities.\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773aaa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] \n",
      "\n",
      "[('8b05af2f-1c49-9939-881c-8b1f772aaef0', '__no_writes__', None)] \n",
      "\n",
      "[('89a09f9d-5eae-feec-007e-12fd708c2038', 'messages', [AIMessage(content='The Prime Minister of India is **Narendra\\u202fModi**. He has been in office since May\\u202f2014.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b', 'created_at': '2026-02-14T07:30:48.192643049Z', 'done': True, 'done_reason': 'stop', 'total_duration': 799386011, 'load_duration': None, 'prompt_eval_count': 4528, 'prompt_eval_duration': None, 'eval_count': 75, 'eval_duration': None, 'logprobs': None, 'model_name': 'gpt-oss:120b', 'model_provider': 'ollama'}, id='lc_run--019c5b0f-245b-7dc1-85f4-8b5d4ed14433-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 4528, 'output_tokens': 75, 'total_tokens': 4603})]), ('89a09f9d-5eae-feec-007e-12fd708c2038', 'branch:to:TodoListMiddleware.after_model', None)] \n",
      "\n",
      "[('2dc18c99-074e-6850-70a5-ac507831fd5c', 'branch:to:model', None)] \n",
      "\n",
      "[('66bfe251-5ca3-bf64-0c84-3441829190c9', 'messages', Overwrite(value=[HumanMessage(content='who is pm of india?', additional_kwargs={}, response_metadata={}, id='ffc18818-10fd-406e-ae01-073879a244b7')])), ('66bfe251-5ca3-bf64-0c84-3441829190c9', 'branch:to:SummarizationMiddleware.before_model', None)] \n",
      "\n",
      "[('498ebcb5-111a-93fd-2c48-f6453f425350', 'messages', [['user', 'who is pm of india?']]), ('498ebcb5-111a-93fd-2c48-f6453f425350', 'branch:to:PatchToolCallsMiddleware.before_agent', None)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in agent_graph.checkpointer.list(config):\n",
    "    print(i[4],\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
